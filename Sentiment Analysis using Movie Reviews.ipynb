{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "388c8df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "import gc\n",
    "import logging\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import string\n",
    "import nltk as nlp\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "#from gensim.test.utils import common_texts\n",
    "#from matplotlib.pyplot as plt\n",
    "#from collections import Counter #like map but worse cuz it senses only the tally --> not for computation :(\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN\n",
    "from tensorflow.keras.models import Sequential, load_model, save_model\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47e3ce06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8324450303373511843\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3146173646\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16601756599967654046\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b95a0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8b87ff",
   "metadata": {},
   "source": [
    "#### LOADING IMDB DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "681057ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(r'..\\\\IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fd22fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45f3a326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d05ea64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efc35164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['sentiment'] = dataframe['sentiment'].replace('positive', 1)\n",
    "dataframe['sentiment'] = dataframe['sentiment'].replace('negative', 0)\n",
    "dataframe.head()\n",
    "#in case of non-binary classes it makes more sense to use label encoder rather than replace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da55ee",
   "metadata": {},
   "source": [
    "#### CHECK FOR NULLS AND DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9085d929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9bfe299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ca4f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.drop_duplicates(subset='review', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02fdd713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49582, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7aef307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2549f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80729c76",
   "metadata": {},
   "source": [
    "#### split into test and train samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "475db5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataframe, test_size = 0.3, random_state = 156, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0adcfd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>This movie is about a group of people who are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20811</th>\n",
       "      <td>This was a less than exciting short film I saw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49519</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;Crackerjack, starring Mick Malloy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32422</th>\n",
       "      <td>Why do I watch movies like this ? - other than...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49066</th>\n",
       "      <td>\"Why did they make them so big? Why didn't the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "3298   This movie is about a group of people who are ...          0\n",
       "20811  This was a less than exciting short film I saw...          0\n",
       "49519  <br /><br />Crackerjack, starring Mick Malloy ...          1\n",
       "32422  Why do I watch movies like this ? - other than...          0\n",
       "49066  \"Why did they make them so big? Why didn't the...          1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a788f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10310</th>\n",
       "      <td>Chaplin was great a silent comedian, but many ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20472</th>\n",
       "      <td>This has got to be one of Australia's best pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31604</th>\n",
       "      <td>A surprising misfire from the usually reliable...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26404</th>\n",
       "      <td>Why do people bitch about this movie and not a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30664</th>\n",
       "      <td>Criticism of the film EVENING, based on the no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "10310  Chaplin was great a silent comedian, but many ...          0\n",
       "20472  This has got to be one of Australia's best pro...          1\n",
       "31604  A surprising misfire from the usually reliable...          0\n",
       "26404  Why do people bitch about this movie and not a...          1\n",
       "30664  Criticism of the film EVENING, based on the no...          1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91201d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98316ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['review'].values\n",
    "y_train = train['sentiment'].values\n",
    "X_test = test['review'].values\n",
    "y_test = test['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "601a0776",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d12fcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d85945",
   "metadata": {},
   "source": [
    "#### REMOVING NON-WORD CHARACTERS FROM THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b8afb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, pattern):\n",
    "    if pattern=='[.]+':\n",
    "        text = re.sub(pattern, '. ', text)\n",
    "    elif pattern ==\"[']\":\n",
    "        text =  re.sub(pattern, ' ', text)\n",
    "    else:\n",
    "        text = re.sub(pattern, '', text)\n",
    "    #print(text, '\\n')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62e14af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vectorize(preprocess)(X_train, '<[^>]*>') #remove markup\n",
    "#print(dataframe.loc[0, 'review'])\n",
    "#dataframe.head()\n",
    "X_test = np.vectorize(preprocess)(X_test, '<[^>]*>') #remove markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47cafa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vectorize(preprocess)(X_train, '[.]+') #remove ... and replace with .\n",
    "#print(dataframe.loc[0, 'review'])\n",
    "#dataframe.head()\n",
    "X_test = np.vectorize(preprocess)(X_test, '[.]+') #remove ... and replace with ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6f5ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vectorize(preprocess)(X_train, '[0-9]+') #remove numbers and replace with none\n",
    "#print(dataframe.loc[0, 'review'])\n",
    "#dataframe.head()\n",
    "X_test = np.vectorize(preprocess)(X_test, '[0-9]+') #remove numbers and replace with none\n",
    "#print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61df9b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vectorize(preprocess)(X_train, \"[']\") #remove ' and replace with \n",
    "#print(dataframe.loc[0, 'review'])\n",
    "#train.head()\n",
    "X_test = np.vectorize(preprocess)(X_test, \"[']\") #remove ' and replace with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0643c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86d225b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vectorize(preprocess)(X_train, '[^\\w\\s]*') #remove everything that's not word space\n",
    "# ' is left to handle contractions\n",
    "#print(dataframe.loc[0, 'review'])\n",
    "X_test = np.vectorize(preprocess)(X_test, '[^\\w\\s]*') #remove everything that's not word space or '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb46e982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This movie is about a group of people who are infected by a powerful manmade virus  They are pursued by government men into the desert The premise of the film is quite interesting but is hampered by the fact that the delivery is extremely boring  At no point does the film engage with the viewer on any level  Granted the miniscule budget is a problem but is not the reason for the film s failure  Much more at fault is the very pofaced delivery  There is a great deal of narration but unfortunately the narrator has an annoyingly overdramatic voice  Very little seems to happen to these people and well before the end you will be rooting for the government men  the sooner they kill the protagonists the sooner the movie will end  A much better title for this film would have been Four People Run About In The Desert With Some Stock Footage Of A Helicopter  Overall very tedious '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16cd0020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this movie is about a group of people who are infected by a powerful manmade virus  they are pursued by government men into the desert the premise of the film is quite interesting but is hampered by the fact that the delivery is extremely boring  at no point does the film engage with the viewer on any level  granted the miniscule budget is a problem but is not the reason for the film s failure  much more at fault is the very pofaced delivery  there is a great deal of narration but unfortunately the narrator has an annoyingly overdramatic voice  very little seems to happen to these people and well before the end you will be rooting for the government men  the sooner they kill the protagonists the sooner the movie will end  a much better title for this film would have been four people run about in the desert with some stock footage of a helicopter  overall very tedious \n"
     ]
    }
   ],
   "source": [
    "X_train = [sentence.lower() for sentence in X_train] #make it lower\n",
    "print(X_train[0])\n",
    "X_test = [sentence.lower() for sentence in X_test] #make it lower\n",
    "#print(dataframe.loc[0, 'review'])\n",
    "#X_test = X_test.str.lower()#make it lower\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa93472",
   "metadata": {},
   "source": [
    "#### DOES IT MAKE SENSE TO REMOVE SOME WORDS TO REDUCE COMPUTATION?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f5d71a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121963"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer()\n",
    "bag = count.fit_transform(X_train)\n",
    "len(count.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a0adb4",
   "metadata": {},
   "source": [
    "#### Got over 2 Lakh words --> it makes sense to remove some words like articles and prepositions out\n",
    "#### Better to remove stop words first (Why? --> documentation wip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4de14a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#something with tfidf\n",
    "#question: does it make sense to do tfidf first and then remove stop words using the nltk corpus or \n",
    "#remove stop words using the corpus first then perform tfidf next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "150a08c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rps24\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbab1086",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english')) #set makes serach O(1)\n",
    "#originally stopwords.words('english') yields a list\n",
    "#print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9cf31724",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps  = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1db337c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_and_stem(text):\n",
    "    text_ = word_tokenize(text)\n",
    "    tokens = []\n",
    "    #print(text_)\n",
    "    for word in text_:\n",
    "        if word not in stop:\n",
    "            tokens.append(ps.stem(word))\n",
    "    #return lemmatization(tokens)\n",
    "    #print(tokens)\n",
    "    text = ' '.join(tokens) #send only tokens sent as a joined sentence\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b4aaa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movi group peopl infect power manmad viru pursu govern men desert premis film quit interest hamper fact deliveri extrem bore point film engag viewer level grant miniscul budget problem reason film failur much fault pofac deliveri great deal narrat unfortun narrat annoyingli overdramat voic littl seem happen peopl well end root govern men sooner kill protagonist sooner movi end much better titl film would four peopl run desert stock footag helicopt overal tediou\n"
     ]
    }
   ],
   "source": [
    "X_train = np.vectorize(remove_stopwords_and_stem)(X_train)\n",
    "X_test = np.vectorize(remove_stopwords_and_stem)(X_test)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11330b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rps24\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "nlp.download('wordnet')\n",
    "reviews = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a80109d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    text_ = word_tokenize(text)\n",
    "    tokens = []\n",
    "    for word in text_:\n",
    "        tokens.append(lemmatizer.lemmatize(word))\n",
    "    text = ' '.join(tokens)\n",
    "    reviews.append(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1fa451a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movi group peopl infect power manmad viru pursu govern men desert premis film quit interest hamper fact deliveri extrem bore point film engag viewer level grant miniscul budget problem reason film failur much fault pofac deliveri great deal narrat unfortun narrat annoyingli overdramat voic littl seem happen peopl well end root govern men sooner kill protagonist sooner movi end much better titl film would four peopl run desert stock footag helicopt overal tediou\n"
     ]
    }
   ],
   "source": [
    "X_train = np.vectorize(lemmatization)(X_train)\n",
    "X_test = np.vectorize(lemmatization)(X_test)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96f9356",
   "metadata": {},
   "source": [
    "#### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53484c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews = np.array(reviews)\n",
    "del reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0d51c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8817e73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0710f1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-07 00:36:41,032 : INFO : collecting all words and their counts\n",
      "2021-10-07 00:36:41,036 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-10-07 00:36:41,268 : INFO : PROGRESS: at sentence #10000, processed 1160527 words, keeping 46426 word types\n",
      "2021-10-07 00:36:41,476 : INFO : PROGRESS: at sentence #20000, processed 2337204 words, keeping 68209 word types\n",
      "2021-10-07 00:36:41,676 : INFO : PROGRESS: at sentence #30000, processed 3510222 words, keeping 86075 word types\n",
      "2021-10-07 00:36:41,896 : INFO : PROGRESS: at sentence #40000, processed 4660315 words, keeping 102157 word types\n",
      "2021-10-07 00:36:42,095 : INFO : collected 116586 word types from a corpus of 5783944 raw words and 49584 sentences\n",
      "2021-10-07 00:36:42,095 : INFO : Creating a fresh vocabulary\n",
      "2021-10-07 00:36:42,588 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 116586 unique words (100.0%% of original 116586, drops 0)', 'datetime': '2021-10-07T00:36:42.588970', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-10-07 00:36:42,592 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 5783944 word corpus (100.0%% of original 5783944, drops 0)', 'datetime': '2021-10-07T00:36:42.592971', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-10-07 00:36:43,370 : INFO : deleting the raw counts dictionary of 116586 items\n",
      "2021-10-07 00:36:43,374 : INFO : sample=0.001 downsamples 35 most-common words\n",
      "2021-10-07 00:36:43,374 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 5463839.524856085 word corpus (94.5%% of prior 5783944)', 'datetime': '2021-10-07T00:36:43.374933', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-10-07 00:36:44,565 : INFO : estimated required memory for 116586 words and 100 dimensions: 151561800 bytes\n",
      "2021-10-07 00:36:44,565 : INFO : resetting layer weights\n",
      "2021-10-07 00:36:44,641 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-10-07T00:36:44.641575', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2021-10-07 00:36:44,645 : INFO : Word2Vec lifecycle event {'msg': 'training model with 5 workers on 116586 vocabulary and 100 features, using sg=2 hs=0 sample=0.001 negative=5 window=3', 'datetime': '2021-10-07T00:36:44.645570', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-10-07 00:36:45,690 : INFO : EPOCH 1 - PROGRESS: at 9.79% examples, 512628 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:36:46,698 : INFO : EPOCH 1 - PROGRESS: at 20.12% examples, 534180 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:36:47,701 : INFO : EPOCH 1 - PROGRESS: at 30.16% examples, 539138 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:36:48,715 : INFO : EPOCH 1 - PROGRESS: at 40.66% examples, 547583 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:36:49,725 : INFO : EPOCH 1 - PROGRESS: at 50.73% examples, 547843 words/s, in_qsize 8, out_qsize 1\n",
      "2021-10-07 00:36:50,745 : INFO : EPOCH 1 - PROGRESS: at 60.94% examples, 548130 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:36:51,746 : INFO : EPOCH 1 - PROGRESS: at 71.96% examples, 553701 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:36:52,750 : INFO : EPOCH 1 - PROGRESS: at 82.29% examples, 554499 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:36:53,761 : INFO : EPOCH 1 - PROGRESS: at 92.54% examples, 554664 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:36:54,416 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-10-07 00:36:54,431 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-07 00:36:54,449 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-07 00:36:54,453 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-07 00:36:54,461 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-07 00:36:54,461 : INFO : EPOCH - 1 : training on 5783944 raw words (5463608 effective words) took 9.8s, 556994 effective words/s\n",
      "2021-10-07 00:36:55,510 : INFO : EPOCH 2 - PROGRESS: at 9.94% examples, 521466 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:36:56,516 : INFO : EPOCH 2 - PROGRESS: at 20.44% examples, 543622 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:36:57,530 : INFO : EPOCH 2 - PROGRESS: at 30.96% examples, 552430 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:36:58,532 : INFO : EPOCH 2 - PROGRESS: at 40.85% examples, 550129 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:36:59,556 : INFO : EPOCH 2 - PROGRESS: at 51.38% examples, 553470 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:00,565 : INFO : EPOCH 2 - PROGRESS: at 62.16% examples, 558383 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:01,569 : INFO : EPOCH 2 - PROGRESS: at 73.36% examples, 563901 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:02,576 : INFO : EPOCH 2 - PROGRESS: at 84.21% examples, 566716 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:03,577 : INFO : EPOCH 2 - PROGRESS: at 94.98% examples, 569274 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:03,988 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-10-07 00:37:03,988 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-07 00:37:04,030 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-07 00:37:04,046 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-07 00:37:04,050 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-07 00:37:04,050 : INFO : EPOCH - 2 : training on 5783944 raw words (5463764 effective words) took 9.6s, 570231 effective words/s\n",
      "2021-10-07 00:37:05,084 : INFO : EPOCH 3 - PROGRESS: at 9.79% examples, 518519 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:06,102 : INFO : EPOCH 3 - PROGRESS: at 20.27% examples, 538894 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:07,107 : INFO : EPOCH 3 - PROGRESS: at 30.48% examples, 544981 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:08,116 : INFO : EPOCH 3 - PROGRESS: at 39.35% examples, 529791 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:09,122 : INFO : EPOCH 3 - PROGRESS: at 49.18% examples, 531707 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:10,138 : INFO : EPOCH 3 - PROGRESS: at 59.09% examples, 532129 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:11,162 : INFO : EPOCH 3 - PROGRESS: at 69.52% examples, 534492 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:12,166 : INFO : EPOCH 3 - PROGRESS: at 79.59% examples, 535264 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:13,166 : INFO : EPOCH 3 - PROGRESS: at 89.83% examples, 538199 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:14,119 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-10-07 00:37:14,123 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-07 00:37:14,136 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-07 00:37:14,136 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-07 00:37:14,140 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-07 00:37:14,144 : INFO : EPOCH - 3 : training on 5783944 raw words (5463899 effective words) took 10.1s, 541615 effective words/s\n",
      "2021-10-07 00:37:15,171 : INFO : EPOCH 4 - PROGRESS: at 9.63% examples, 512469 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:16,193 : INFO : EPOCH 4 - PROGRESS: at 20.27% examples, 540182 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:17,212 : INFO : EPOCH 4 - PROGRESS: at 30.65% examples, 546261 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:18,216 : INFO : EPOCH 4 - PROGRESS: at 39.35% examples, 528662 words/s, in_qsize 9, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-07 00:37:19,225 : INFO : EPOCH 4 - PROGRESS: at 48.16% examples, 519471 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:20,252 : INFO : EPOCH 4 - PROGRESS: at 57.59% examples, 516678 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:21,259 : INFO : EPOCH 4 - PROGRESS: at 68.11% examples, 523794 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:22,276 : INFO : EPOCH 4 - PROGRESS: at 78.56% examples, 527467 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:23,276 : INFO : EPOCH 4 - PROGRESS: at 89.49% examples, 535320 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:24,197 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-10-07 00:37:24,215 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-07 00:37:24,230 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-07 00:37:24,230 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-07 00:37:24,242 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-07 00:37:24,242 : INFO : EPOCH - 4 : training on 5783944 raw words (5464612 effective words) took 10.1s, 541404 effective words/s\n",
      "2021-10-07 00:37:25,274 : INFO : EPOCH 5 - PROGRESS: at 9.62% examples, 512713 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:26,284 : INFO : EPOCH 5 - PROGRESS: at 20.44% examples, 547089 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:27,298 : INFO : EPOCH 5 - PROGRESS: at 30.32% examples, 542772 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:28,317 : INFO : EPOCH 5 - PROGRESS: at 40.50% examples, 545363 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:29,328 : INFO : EPOCH 5 - PROGRESS: at 50.88% examples, 549547 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:30,346 : INFO : EPOCH 5 - PROGRESS: at 61.30% examples, 551166 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:31,356 : INFO : EPOCH 5 - PROGRESS: at 72.11% examples, 554347 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:32,369 : INFO : EPOCH 5 - PROGRESS: at 82.64% examples, 555499 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:33,387 : INFO : EPOCH 5 - PROGRESS: at 93.00% examples, 556331 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-07 00:37:34,010 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-10-07 00:37:34,022 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-07 00:37:34,036 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-07 00:37:34,038 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-07 00:37:34,050 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-07 00:37:34,050 : INFO : EPOCH - 5 : training on 5783944 raw words (5464455 effective words) took 9.8s, 557563 effective words/s\n",
      "2021-10-07 00:37:34,054 : INFO : Word2Vec lifecycle event {'msg': 'training on 28919720 raw words (27320338 effective words) took 49.4s, 552963 effective words/s', 'datetime': '2021-10-07T00:37:34.054711', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-10-07 00:37:34,054 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=116586, vector_size=100, alpha=0.025)', 'datetime': '2021-10-07T00:37:34.054711', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = Word2Vec(all_reviews, window = 3, min_count = 1, sg = 2, workers = 5) #sg --> skipgram\n",
    "#workers --> number of threads in useb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9f117b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-07 00:37:34,218 : INFO : storing 116586x100 projection weights into ../word_embeddings.txt\n"
     ]
    }
   ],
   "source": [
    "#need to save model here\n",
    "word2vec_model.wv.save_word2vec_format('../word_embeddings.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c90b9a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-07 00:37:43,438 : INFO : loading projection weights from ../word_embeddings.txt\n",
      "2021-10-07 00:37:55,468 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (116586, 100) matrix of type float32 from ../word_embeddings.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2021-10-07T00:37:55.468918', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = KeyedVectors.load_word2vec_format('../word_embeddings.txt', binary = False, unicode_errors = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3e942d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54459554"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.similarity('saw', 'may')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3fb18e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5877179"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.similarity('saw', 'say')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "acbda6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6005263"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.similarity('say', 'may')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b4c57eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75372225"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.similarity('gangsta', 'latino')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1006ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116586"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2vec_model.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab8a29e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f9d11f",
   "metadata": {},
   "source": [
    "#### load dictionary of word to vectors --> from gensim instance to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c46a721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = {}\n",
    "with open('../word_embeddings.txt', encoding = 'utf-8') as f:\n",
    "    #page = f.read()\n",
    "    for line in f:\n",
    "        record = line.split()\n",
    "        #print(record[0])\n",
    "        #word = record[0]\n",
    "        embedding[record[0]] = np.asarray(record[1:])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "225c2aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116587\n"
     ]
    }
   ],
   "source": [
    "print(len(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "020c4a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465d02ef",
   "metadata": {},
   "source": [
    "#### CREATING TENSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "76f2955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_tensor = Tokenizer()\n",
    "token_tensor.fit_on_texts(all_reviews)\n",
    "maxim = 0\n",
    "for  review in all_reviews:\n",
    "    maxim = max(maxim, len(review))\n",
    "X_train_token = token_tensor.texts_to_sequences(X_train)\n",
    "X_train_pad = pad_sequences(X_train_token, maxlen = maxim, padding='post')\n",
    "X_test_token = token_tensor.texts_to_sequences(X_test)\n",
    "X_test_pad = pad_sequences(X_test_token, maxlen = maxim, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "af37c8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34707, 1406)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f3bb5400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34707,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a58bb547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14875, 1406)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fbe72488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14875,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c1576bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = token_tensor.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cb6eef6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116587\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(vocabulary) + 1\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "efb20928",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_matrix = np.zeros((vocabulary_size, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b568605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i in vocabulary.items():\n",
    "    vector = embedding.get(word)\n",
    "    if vector is not None:\n",
    "        embed_matrix[i] = vector\n",
    "#create a np array of all vector values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3e1f1865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116587, 100)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "359deb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34707, 1406)\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train_pad.shape\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a6471d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89064bc4",
   "metadata": {},
   "source": [
    "#### simple rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "032715af",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "session = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c1308c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-07 00:39:41,723 : WARNING : From C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "simple_rnn = Sequential()\n",
    "embedding_layer = Embedding(vocabulary_size, \n",
    "                            256, \n",
    "                            embeddings_initializer = Constant(embed_matrix), \n",
    "                            input_length = maxim, \n",
    "                            trainable = False)\n",
    "simple_rnn.add(embedding_layer)\n",
    "simple_rnn.add(SimpleRNN(units = 32, input_shape = input_shape, dropout = 0.2, activation = 'relu', recurrent_dropout = 0.2))\n",
    "simple_rnn.add(Dense(units = 16, activation = 'relu'))\n",
    "simple_rnn.add(Dense(units=1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "57cf34be",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rnn.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "55ebde62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1406, 256)         29846272  \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 32)                9248      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 29,856,065\n",
      "Trainable params: 9,793\n",
      "Non-trainable params: 29,846,272\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "81bd624e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d8e68afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-07 00:39:48,923 : WARNING : `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('..\\\\models\\\\simple_rnn.h5', \n",
    "                             monitor='val_acc', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=False,\n",
    "                             mode='auto', \n",
    "                             period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "90b9f8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24294 samples, validate on 10413 samples\n",
      "WARNING:tensorflow:From C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-07 00:39:52,278 : WARNING : From C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6571 - acc: 0.5006\n",
      "Epoch 00001: val_acc improved from -inf to 0.50936, saving model to ..\\models\\simple_rnn.h5\n",
      "24294/24294 [==============================] - 585s 24ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 2/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6584 - acc: 0.5005\n",
      "Epoch 00002: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 630s 26ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 3/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6597 - acc: 0.5005\n",
      "Epoch 00003: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 333s 14ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 4/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6571 - acc: 0.5006\n",
      "Epoch 00004: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 334s 14ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 5/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6590 - acc: 0.5005\n",
      "Epoch 00005: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 336s 14ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 6/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6559 - acc: 0.5007\n",
      "Epoch 00006: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 336s 14ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 7/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6597 - acc: 0.5005\n",
      "Epoch 00007: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 336s 14ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 8/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6584 - acc: 0.5005\n",
      "Epoch 00008: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 337s 14ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 9/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6565 - acc: 0.5007\n",
      "Epoch 00009: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 338s 14ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 10/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6565 - acc: 0.5007\n",
      "Epoch 00010: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 361s 15ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 11/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6565 - acc: 0.5007\n",
      "Epoch 00011: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 333s 14ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 12/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6571 - acc: 0.5006\n",
      "Epoch 00012: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 334s 14ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 13/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6584 - acc: 0.5005\n",
      "Epoch 00013: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 332s 14ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 14/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6571 - acc: 0.5006\n",
      "Epoch 00014: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 332s 14ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 15/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6584 - acc: 0.5005\n",
      "Epoch 00015: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 331s 14ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 16/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6603 - acc: 0.5004\n",
      "Epoch 00016: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 331s 14ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 17/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6571 - acc: 0.5006\n",
      "Epoch 00017: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 329s 14ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 18/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6578 - acc: 0.5006\n",
      "Epoch 00018: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 327s 13ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 19/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6552 - acc: 0.5007\n",
      "Epoch 00019: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 433s 18ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 20/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6559 - acc: 0.5007\n",
      "Epoch 00020: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 532s 22ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 21/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6584 - acc: 0.5005\n",
      "Epoch 00021: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 528s 22ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 22/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6590 - acc: 0.5005\n",
      "Epoch 00022: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 529s 22ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 23/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6571 - acc: 0.5006\n",
      "Epoch 00023: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 441s 18ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 24/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6565 - acc: 0.5007\n",
      "Epoch 00024: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 323s 13ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n",
      "Epoch 25/25\n",
      "24256/24294 [============================>.] - ETA: 0s - loss: 7.6597 - acc: 0.5005\n",
      "Epoch 00025: val_acc did not improve from 0.50936\n",
      "24294/24294 [==============================] - 324s 13ms/sample - loss: 7.6578 - acc: 0.5006 - val_loss: 7.5230 - val_acc: 0.5094\n"
     ]
    }
   ],
   "source": [
    "simple_rnn_history = simple_rnn.fit(X_train_pad, \n",
    "                                    y_train, \n",
    "                                    epochs=25,\n",
    "                                    batch_size=64,\n",
    "                                    validation_split=0.3, \n",
    "                                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d1bd391d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del simple_rnn\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "954435a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-07 03:21:42,322 : WARNING : From C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-07 03:22:43,382 : WARNING : From C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-07 03:22:43,383 : WARNING : From C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-07 03:22:43,386 : WARNING : From C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "simple_rnn = load_model('..\\\\models\\\\simple_rnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a39434",
   "metadata": {},
   "source": [
    "#### metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f6a80ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = simple_rnn.predict(X_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "32186348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53314f90",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ee53f7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 7456]\n",
      " [   0 7419]]\n"
     ]
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred)  \n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a257115f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d974fad",
   "metadata": {},
   "source": [
    "#### classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0ced8529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      7456\n",
      "           1       0.50      1.00      0.67      7419\n",
      "\n",
      "    accuracy                           0.50     14875\n",
      "   macro avg       0.25      0.50      0.33     14875\n",
      "weighted avg       0.25      0.50      0.33     14875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "print('Report: \\n',report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa4b22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
