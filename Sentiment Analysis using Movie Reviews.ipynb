{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "388c8df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "import gc\n",
    "import logging\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import string\n",
    "import nltk as nlp\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "#from gensim.test.utils import common_texts\n",
    "#from matplotlib.pyplot as plt\n",
    "#from collections import Counter #like map but worse cuz it senses only the tally --> not for computation :(\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47e3ce06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 916339987779280946\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3156659406\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11513661521220419997\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b95a0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8b87ff",
   "metadata": {},
   "source": [
    "#### LOADING IMDB DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "681057ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(r'..\\\\IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fd22fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45f3a326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  negative\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d05ea64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efc35164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['sentiment'] = dataframe['sentiment'].replace('positive', 1)\n",
    "dataframe['sentiment'] = dataframe['sentiment'].replace('negative', 0)\n",
    "dataframe.head()\n",
    "#in case of non-binary classes it makes more sense to use label encoder rather than replace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da55ee",
   "metadata": {},
   "source": [
    "#### CHECK FOR NULLS AND DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9085d929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9bfe299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ca4f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.drop_duplicates(subset='review', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02fdd713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49582, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7aef307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2549f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80729c76",
   "metadata": {},
   "source": [
    "#### split into test and train samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "475db5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataframe, test_size = 0.3, random_state = 156, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0adcfd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>This movie is about a group of people who are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20811</th>\n",
       "      <td>This was a less than exciting short film I saw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49519</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;Crackerjack, starring Mick Malloy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32422</th>\n",
       "      <td>Why do I watch movies like this ? - other than...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49066</th>\n",
       "      <td>\"Why did they make them so big? Why didn't the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "3298   This movie is about a group of people who are ...          0\n",
       "20811  This was a less than exciting short film I saw...          0\n",
       "49519  <br /><br />Crackerjack, starring Mick Malloy ...          1\n",
       "32422  Why do I watch movies like this ? - other than...          0\n",
       "49066  \"Why did they make them so big? Why didn't the...          1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a788f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10310</th>\n",
       "      <td>Chaplin was great a silent comedian, but many ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20472</th>\n",
       "      <td>This has got to be one of Australia's best pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31604</th>\n",
       "      <td>A surprising misfire from the usually reliable...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26404</th>\n",
       "      <td>Why do people bitch about this movie and not a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30664</th>\n",
       "      <td>Criticism of the film EVENING, based on the no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "10310  Chaplin was great a silent comedian, but many ...          0\n",
       "20472  This has got to be one of Australia's best pro...          1\n",
       "31604  A surprising misfire from the usually reliable...          0\n",
       "26404  Why do people bitch about this movie and not a...          1\n",
       "30664  Criticism of the film EVENING, based on the no...          1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91201d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98316ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['review'].values\n",
    "y_train = train['sentiment'].values\n",
    "X_test = test['review'].values\n",
    "y_test = test['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "601a0776",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d12fcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d85945",
   "metadata": {},
   "source": [
    "#### REMOVING NON-WORD CHARACTERS FROM THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b8afb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, pattern):\n",
    "    if pattern=='[.]+':\n",
    "        text = re.sub(pattern, '. ', text)\n",
    "    elif pattern ==\"[']\":\n",
    "        text =  re.sub(pattern, ' ', text)\n",
    "    else:\n",
    "        text = re.sub(pattern, '', text)\n",
    "    #print(text, '\\n')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62e14af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vectorize(preprocess)(X_train, '<[^>]*>') #remove markup\n",
    "#print(dataframe.loc[0, 'review'])\n",
    "#dataframe.head()\n",
    "X_test = np.vectorize(preprocess)(X_test, '<[^>]*>') #remove markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47cafa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vectorize(preprocess)(X_train, '[.]+') #remove ... and replace with .\n",
    "#print(dataframe.loc[0, 'review'])\n",
    "#dataframe.head()\n",
    "X_test = np.vectorize(preprocess)(X_test, '[.]+') #remove ... and replace with ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6f5ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vectorize(preprocess)(X_train, '[0-9]+') #remove numbers and replace with none\n",
    "#print(dataframe.loc[0, 'review'])\n",
    "#dataframe.head()\n",
    "X_test = np.vectorize(preprocess)(X_test, '[0-9]+') #remove numbers and replace with none\n",
    "#print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61df9b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vectorize(preprocess)(X_train, \"[']\") #remove ' and replace with \n",
    "#print(dataframe.loc[0, 'review'])\n",
    "#train.head()\n",
    "X_test = np.vectorize(preprocess)(X_test, \"[']\") #remove ' and replace with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0643c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86d225b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vectorize(preprocess)(X_train, '[^\\w\\s]*') #remove everything that's not word space\n",
    "# ' is left to handle contractions\n",
    "#print(dataframe.loc[0, 'review'])\n",
    "X_test = np.vectorize(preprocess)(X_test, '[^\\w\\s]*') #remove everything that's not word space or '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb46e982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This movie is about a group of people who are infected by a powerful manmade virus  They are pursued by government men into the desert The premise of the film is quite interesting but is hampered by the fact that the delivery is extremely boring  At no point does the film engage with the viewer on any level  Granted the miniscule budget is a problem but is not the reason for the film s failure  Much more at fault is the very pofaced delivery  There is a great deal of narration but unfortunately the narrator has an annoyingly overdramatic voice  Very little seems to happen to these people and well before the end you will be rooting for the government men  the sooner they kill the protagonists the sooner the movie will end  A much better title for this film would have been Four People Run About In The Desert With Some Stock Footage Of A Helicopter  Overall very tedious '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16cd0020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this movie is about a group of people who are infected by a powerful manmade virus  they are pursued by government men into the desert the premise of the film is quite interesting but is hampered by the fact that the delivery is extremely boring  at no point does the film engage with the viewer on any level  granted the miniscule budget is a problem but is not the reason for the film s failure  much more at fault is the very pofaced delivery  there is a great deal of narration but unfortunately the narrator has an annoyingly overdramatic voice  very little seems to happen to these people and well before the end you will be rooting for the government men  the sooner they kill the protagonists the sooner the movie will end  a much better title for this film would have been four people run about in the desert with some stock footage of a helicopter  overall very tedious \n"
     ]
    }
   ],
   "source": [
    "X_train = [sentence.lower() for sentence in X_train] #make it lower\n",
    "print(X_train[0])\n",
    "X_test = [sentence.lower() for sentence in X_test] #make it lower\n",
    "#print(dataframe.loc[0, 'review'])\n",
    "#X_test = X_test.str.lower()#make it lower\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa93472",
   "metadata": {},
   "source": [
    "#### DOES IT MAKE SENSE TO REMOVE SOME WORDS TO REDUCE COMPUTATION?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f5d71a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121963"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer()\n",
    "bag = count.fit_transform(X_train)\n",
    "len(count.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a0adb4",
   "metadata": {},
   "source": [
    "#### Got over 2 Lakh words --> it makes sense to remove some words like articles and prepositions out\n",
    "#### Better to remove stop words first (Why? --> documentation wip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4de14a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#something with tfidf\n",
    "#question: does it make sense to do tfidf first and then remove stop words using the nltk corpus or \n",
    "#remove stop words using the corpus first then perform tfidf next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "150a08c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rps24\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbab1086",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english')) #set makes serach O(1)\n",
    "#originally stopwords.words('english') yields a list\n",
    "#print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9cf31724",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps  = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1db337c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_and_stem(text):\n",
    "    text_ = word_tokenize(text)\n",
    "    tokens = []\n",
    "    #print(text_)\n",
    "    for word in text_:\n",
    "        if word not in stop:\n",
    "            tokens.append(ps.stem(word))\n",
    "    #return lemmatization(tokens)\n",
    "    #print(tokens)\n",
    "    text = ' '.join(tokens) #send only tokens sent as a joined sentence\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b4aaa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movi group peopl infect power manmad viru pursu govern men desert premis film quit interest hamper fact deliveri extrem bore point film engag viewer level grant miniscul budget problem reason film failur much fault pofac deliveri great deal narrat unfortun narrat annoyingli overdramat voic littl seem happen peopl well end root govern men sooner kill protagonist sooner movi end much better titl film would four peopl run desert stock footag helicopt overal tediou\n"
     ]
    }
   ],
   "source": [
    "X_train = np.vectorize(remove_stopwords_and_stem)(X_train)\n",
    "X_test = np.vectorize(remove_stopwords_and_stem)(X_test)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11330b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rps24\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "nlp.download('wordnet')\n",
    "reviews = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a80109d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    text_ = word_tokenize(text)\n",
    "    tokens = []\n",
    "    for word in text_:\n",
    "        tokens.append(lemmatizer.lemmatize(word))\n",
    "    text = ' '.join(tokens)\n",
    "    reviews.append(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1fa451a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movi group peopl infect power manmad viru pursu govern men desert premis film quit interest hamper fact deliveri extrem bore point film engag viewer level grant miniscul budget problem reason film failur much fault pofac deliveri great deal narrat unfortun narrat annoyingli overdramat voic littl seem happen peopl well end root govern men sooner kill protagonist sooner movi end much better titl film would four peopl run desert stock footag helicopt overal tediou\n"
     ]
    }
   ],
   "source": [
    "X_train = np.vectorize(lemmatization)(X_train)\n",
    "X_test = np.vectorize(lemmatization)(X_test)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96f9356",
   "metadata": {},
   "source": [
    "#### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53484c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "all_reviews = np.array(reviews)\n",
    "del reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0d51c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8817e73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0710f1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 22:15:48,667 : INFO : collecting all words and their counts\n",
      "2021-10-04 22:15:48,669 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-10-04 22:15:48,867 : INFO : PROGRESS: at sentence #10000, processed 1160527 words, keeping 46426 word types\n",
      "2021-10-04 22:15:49,073 : INFO : PROGRESS: at sentence #20000, processed 2337204 words, keeping 68209 word types\n",
      "2021-10-04 22:15:49,258 : INFO : PROGRESS: at sentence #30000, processed 3510222 words, keeping 86075 word types\n",
      "2021-10-04 22:15:49,456 : INFO : PROGRESS: at sentence #40000, processed 4660315 words, keeping 102157 word types\n",
      "2021-10-04 22:15:49,649 : INFO : collected 116586 word types from a corpus of 5783944 raw words and 49584 sentences\n",
      "2021-10-04 22:15:49,650 : INFO : Loading a fresh vocabulary\n",
      "2021-10-04 22:15:49,815 : INFO : effective_min_count=1 retains 116586 unique words (100% of original 116586, drops 0)\n",
      "2021-10-04 22:15:49,816 : INFO : effective_min_count=1 leaves 5783944 word corpus (100% of original 5783944, drops 0)\n",
      "2021-10-04 22:15:50,082 : INFO : deleting the raw counts dictionary of 116586 items\n",
      "2021-10-04 22:15:50,086 : INFO : sample=0.001 downsamples 35 most-common words\n",
      "2021-10-04 22:15:50,086 : INFO : downsampling leaves estimated 5463839 word corpus (94.5% of prior 5783944)\n",
      "2021-10-04 22:15:50,368 : INFO : estimated required memory for 116586 words and 256 dimensions: 297061128 bytes\n",
      "2021-10-04 22:15:50,368 : INFO : resetting layer weights\n",
      "2021-10-04 22:16:07,203 : INFO : training model with 5 workers on 116586 vocabulary and 256 features, using sg=2 hs=0 sample=0.001 negative=5 window=3\n",
      "2021-10-04 22:16:08,210 : INFO : EPOCH 1 - PROGRESS: at 7.94% examples, 429611 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:09,224 : INFO : EPOCH 1 - PROGRESS: at 16.30% examples, 440466 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:10,233 : INFO : EPOCH 1 - PROGRESS: at 24.75% examples, 445205 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:11,250 : INFO : EPOCH 1 - PROGRESS: at 33.53% examples, 453221 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:12,260 : INFO : EPOCH 1 - PROGRESS: at 42.25% examples, 457203 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:13,304 : INFO : EPOCH 1 - PROGRESS: at 51.20% examples, 460437 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:14,334 : INFO : EPOCH 1 - PROGRESS: at 60.59% examples, 466050 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:15,349 : INFO : EPOCH 1 - PROGRESS: at 70.34% examples, 472301 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:16,354 : INFO : EPOCH 1 - PROGRESS: at 80.28% examples, 478707 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:17,361 : INFO : EPOCH 1 - PROGRESS: at 88.41% examples, 475591 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:18,373 : INFO : EPOCH 1 - PROGRESS: at 97.86% examples, 478575 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:18,542 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-10-04 22:16:18,589 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-04 22:16:18,613 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-04 22:16:18,623 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-04 22:16:18,632 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-04 22:16:18,633 : INFO : EPOCH - 1 : training on 5783944 raw words (5463785 effective words) took 11.4s, 478214 effective words/s\n",
      "2021-10-04 22:16:19,680 : INFO : EPOCH 2 - PROGRESS: at 8.11% examples, 422218 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:20,694 : INFO : EPOCH 2 - PROGRESS: at 16.49% examples, 436584 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:21,698 : INFO : EPOCH 2 - PROGRESS: at 26.11% examples, 464201 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:22,700 : INFO : EPOCH 2 - PROGRESS: at 35.27% examples, 473892 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:23,716 : INFO : EPOCH 2 - PROGRESS: at 44.31% examples, 476900 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:24,717 : INFO : EPOCH 2 - PROGRESS: at 53.10% examples, 478557 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:25,725 : INFO : EPOCH 2 - PROGRESS: at 61.63% examples, 476508 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:26,757 : INFO : EPOCH 2 - PROGRESS: at 71.25% examples, 479315 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:27,765 : INFO : EPOCH 2 - PROGRESS: at 80.90% examples, 483791 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:28,804 : INFO : EPOCH 2 - PROGRESS: at 90.50% examples, 486018 words/s, in_qsize 10, out_qsize 0\n",
      "2021-10-04 22:16:29,711 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-10-04 22:16:29,748 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-04 22:16:29,791 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-04 22:16:29,792 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-04 22:16:29,796 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-04 22:16:29,796 : INFO : EPOCH - 2 : training on 5783944 raw words (5463860 effective words) took 11.2s, 489605 effective words/s\n",
      "2021-10-04 22:16:30,825 : INFO : EPOCH 3 - PROGRESS: at 9.11% examples, 484069 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:31,832 : INFO : EPOCH 3 - PROGRESS: at 17.93% examples, 478526 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:32,836 : INFO : EPOCH 3 - PROGRESS: at 27.21% examples, 486511 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:33,861 : INFO : EPOCH 3 - PROGRESS: at 36.16% examples, 485730 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:34,862 : INFO : EPOCH 3 - PROGRESS: at 44.48% examples, 480336 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:35,864 : INFO : EPOCH 3 - PROGRESS: at 53.42% examples, 482883 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:36,865 : INFO : EPOCH 3 - PROGRESS: at 62.69% examples, 486007 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:37,868 : INFO : EPOCH 3 - PROGRESS: at 72.45% examples, 490545 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:38,882 : INFO : EPOCH 3 - PROGRESS: at 81.94% examples, 492494 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:39,886 : INFO : EPOCH 3 - PROGRESS: at 91.38% examples, 494569 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:40,738 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-10-04 22:16:40,754 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-04 22:16:40,811 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-04 22:16:40,813 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-04 22:16:40,813 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-04 22:16:40,814 : INFO : EPOCH - 3 : training on 5783944 raw words (5463991 effective words) took 11.0s, 496120 effective words/s\n",
      "2021-10-04 22:16:41,834 : INFO : EPOCH 4 - PROGRESS: at 8.77% examples, 470301 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:42,834 : INFO : EPOCH 4 - PROGRESS: at 18.09% examples, 487128 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:43,850 : INFO : EPOCH 4 - PROGRESS: at 27.36% examples, 490228 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:44,859 : INFO : EPOCH 4 - PROGRESS: at 36.33% examples, 490384 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:45,866 : INFO : EPOCH 4 - PROGRESS: at 44.31% examples, 479663 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:46,895 : INFO : EPOCH 4 - PROGRESS: at 53.10% examples, 478800 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:47,898 : INFO : EPOCH 4 - PROGRESS: at 62.16% examples, 480973 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:48,899 : INFO : EPOCH 4 - PROGRESS: at 71.44% examples, 482737 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:49,911 : INFO : EPOCH 4 - PROGRESS: at 80.75% examples, 484679 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:50,912 : INFO : EPOCH 4 - PROGRESS: at 89.67% examples, 484889 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:51,912 : INFO : EPOCH 4 - PROGRESS: at 98.81% examples, 486716 words/s, in_qsize 7, out_qsize 0\n",
      "2021-10-04 22:16:51,999 : INFO : worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 22:16:52,000 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-04 22:16:52,012 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-04 22:16:52,038 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-04 22:16:52,064 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-04 22:16:52,065 : INFO : EPOCH - 4 : training on 5783944 raw words (5463401 effective words) took 11.2s, 485801 effective words/s\n",
      "2021-10-04 22:16:53,099 : INFO : EPOCH 5 - PROGRESS: at 8.77% examples, 465325 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:54,105 : INFO : EPOCH 5 - PROGRESS: at 17.38% examples, 464652 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:55,119 : INFO : EPOCH 5 - PROGRESS: at 26.46% examples, 472577 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:56,143 : INFO : EPOCH 5 - PROGRESS: at 36.00% examples, 482237 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:57,177 : INFO : EPOCH 5 - PROGRESS: at 44.31% examples, 474467 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:58,198 : INFO : EPOCH 5 - PROGRESS: at 52.93% examples, 473479 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:16:59,240 : INFO : EPOCH 5 - PROGRESS: at 62.35% examples, 476490 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:17:00,282 : INFO : EPOCH 5 - PROGRESS: at 71.96% examples, 478741 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:17:01,311 : INFO : EPOCH 5 - PROGRESS: at 81.42% examples, 481152 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:17:02,344 : INFO : EPOCH 5 - PROGRESS: at 90.87% examples, 482894 words/s, in_qsize 9, out_qsize 0\n",
      "2021-10-04 22:17:03,275 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-10-04 22:17:03,284 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-10-04 22:17:03,302 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-10-04 22:17:03,334 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-10-04 22:17:03,341 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-10-04 22:17:03,342 : INFO : EPOCH - 5 : training on 5783944 raw words (5463997 effective words) took 11.3s, 484898 effective words/s\n",
      "2021-10-04 22:17:03,342 : INFO : training on a 28919720 raw words (27319034 effective words) took 56.1s, 486634 effective words/s\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = Word2Vec(all_reviews, window = 3, min_count = 1, sg = 2, size = 256, workers = 5) #sg --> skipgram\n",
    "#workers --> number of threads in useb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9f117b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 22:17:03,354 : INFO : storing 116586x256 projection weights into ../word_embeddings.txt\n"
     ]
    }
   ],
   "source": [
    "#need to save model here\n",
    "word2vec_model.wv.save_word2vec_format('../word_embeddings.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c90b9a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-06 12:03:48,667 : INFO : loading projection weights from ../word_embeddings.txt\n",
      "2021-10-06 12:04:19,790 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (116586, 256) matrix of type float32 from ../word_embeddings.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2021-10-06T12:04:19.790818', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = KeyedVectors.load_word2vec_format('../word_embeddings.txt', binary = False, unicode_errors = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3e942d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40047997"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.similarity('saw', 'may')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3fb18e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4299609"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.similarity('saw', 'say')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "acbda6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46379727"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.similarity('say', 'may')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b4c57eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68123794"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.similarity('gangsta', 'latino')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1006ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116586"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2vec_model.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab8a29e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f9d11f",
   "metadata": {},
   "source": [
    "#### load dictionary of word to vectors --> from gensim instance to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c46a721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = {}\n",
    "with open('../word_embeddings.txt', encoding = 'utf-8') as f:\n",
    "    #page = f.read()\n",
    "    for line in f:\n",
    "        record = line.split()\n",
    "        #print(record[0])\n",
    "        #word = record[0]\n",
    "        embedding[record[0]] = np.asarray(record[1:])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "225c2aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116587\n"
     ]
    }
   ],
   "source": [
    "print(len(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "020c4a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465d02ef",
   "metadata": {},
   "source": [
    "#### CREATING TENSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "76f2955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_tensor = Tokenizer()\n",
    "token_tensor.fit_on_texts(all_reviews)\n",
    "maxim = 0\n",
    "for  review in all_reviews:\n",
    "    maxim = max(maxim, len(review))\n",
    "X_train_token = token_tensor.texts_to_sequences(X_train)\n",
    "X_train_pad = pad_sequences(X_train_token, maxlen = maxim, padding='post')\n",
    "X_test_token = token_tensor.texts_to_sequences(X_test)\n",
    "X_test_pad = pad_sequences(X_test_token, maxlen = maxim, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "af37c8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34707, 1406)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f3bb5400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34707,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "93a25d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14875, 1406)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9e98fd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14875,)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c1576bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = token_tensor.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb6eef6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116587\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(vocabulary) + 1\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "efb20928",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_matrix = np.zeros((vocabulary_size, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b568605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i in vocabulary.items():\n",
    "    vector = embedding.get(word)\n",
    "    if vector is not None:\n",
    "        embed_matrix[i] = vector\n",
    "#create a np array of all vector values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3e1f1865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116587, 256)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "359deb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34707, 1406)\n"
     ]
    }
   ],
   "source": [
    "3input_shape = X_train_pad.shape\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89064bc4",
   "metadata": {},
   "source": [
    "#### simple rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c1308c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rnn = Sequential()\n",
    "embedding_layer = Embedding(vocabulary_size, \n",
    "                            256, \n",
    "                            embeddings_initializer = Constant(embed_matrix), \n",
    "                            input_length = maxim, \n",
    "                            trainable = False)\n",
    "simple_rnn.add(embedding_layer)\n",
    "simple_rnn.add(SimpleRNN(units = 32, input_shape = input_shape, dropout = 0.2, activation = 'relu', recurrent_dropout = 0.2))\n",
    "simple_rnn.add(Dense(units = 16, activation = 'relu'))\n",
    "simple_rnn.add(Dense(units=1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "14d25c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rnn.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8a5e0a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 1406, 256)         29846272  \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 32)                9248      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 29,856,065\n",
      "Trainable params: 9,793\n",
      "Non-trainable params: 29,846,272\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0e663e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34707 samples, validate on 14875 samples\n",
      "Epoch 1/25\n",
      " - 248s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 2/25\n",
      " - 259s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 3/25\n",
      " - 292s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 4/25\n",
      " - 382s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 5/25\n",
      " - 381s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 6/25\n",
      " - 385s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 7/25\n",
      " - 380s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 8/25\n",
      " - 363s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 9/25\n",
      " - 250s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 10/25\n",
      " - 253s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 11/25\n",
      " - 253s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 12/25\n",
      " - 254s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 13/25\n",
      " - 260s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 14/25\n",
      " - 254s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 15/25\n",
      " - 257s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 16/25\n",
      " - 287s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 17/25\n",
      " - 287s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 18/25\n",
      " - 254s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 19/25\n",
      " - 255s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 20/25\n",
      " - 253s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 21/25\n",
      " - 255s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 22/25\n",
      " - 261s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 23/25\n",
      " - 253s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 24/25\n",
      " - 253s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n",
      "Epoch 25/25\n",
      " - 253s - loss: 7.9200 - acc: 0.5032 - val_loss: 7.9910 - val_acc: 0.4988\n"
     ]
    }
   ],
   "source": [
    "simple_rnn_history = simple_rnn.fit(X_train_pad, \n",
    "                                    y_train, \n",
    "                                    batch_size=128, \n",
    "                                    epochs=25, \n",
    "                                    validation_data=(X_test_pad, y_test), \n",
    "                                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6c65cca5",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-7ef207f61bb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msimple_rnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'..\\\\simple_rnn.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_model\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m     \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[1;34m'config'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         },\n\u001b[1;32m--> 103\u001b[1;33m         default=serialization.get_json_type).encode('utf8')\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[0mmodel_weights_group\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\h5py\\_hl\\attrs.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0muse\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmethods\u001b[0m \u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmodify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \"\"\"\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwith_phil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\h5py\\_hl\\attrs.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, name, data, shape, dtype)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[1;31m# We need this to handle special string types.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[1;31m# Make HDF5 datatype and dataspace for the H5A calls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "simple_rnn.save('..\\\\simple_rnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2023eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del simple_rnn\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d0e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rnn = load_model('..\\simple_rnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a39434",
   "metadata": {},
   "source": [
    "#### metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2640fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict with validation set \n",
    "#do everything with validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f6a80ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = simple_rnn.predict(X_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "32186348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf926a1",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ff01b05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 7456]\n",
      " [   0 7419]]\n"
     ]
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred)  \n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8d7b534f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6995df46",
   "metadata": {},
   "source": [
    "#### classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ce60ec6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      7456\n",
      "           1       0.50      1.00      0.67      7419\n",
      "\n",
      "    accuracy                           0.50     14875\n",
      "   macro avg       0.25      0.50      0.33     14875\n",
      "weighted avg       0.25      0.50      0.33     14875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rps24\\anaconda3\\envs\\senti-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "print('Report: \\n',report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3409092d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b4fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
